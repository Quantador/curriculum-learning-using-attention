{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3032e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mloscratch/homes/wahidy/conda/envs/curriculum/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/mloscratch/homes/wahidy/conda/envs/curriculum/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "\n",
    "from config import Config\n",
    "from data import get_tokenizer, make_mixed_chunks, MixedLMDataset\n",
    "from model import TinyGPT, AttentionRouter\n",
    "from training import train_baseline, train_router, compare_runs\n",
    "from metrics import MetricsTracker, DiversityTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02fb2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e329d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    cfg = Config()\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    tokenizer = get_tokenizer()\n",
    "\n",
    "    print(\"\\n=== Building datasets ===\")\n",
    "    train_chunks = make_mixed_chunks(\"train\", cfg, tokenizer)\n",
    "    val_chunks = make_mixed_chunks(\"validation\", cfg, tokenizer)\n",
    "\n",
    "    train_ds = MixedLMDataset(train_chunks)\n",
    "    val_ds = MixedLMDataset(val_chunks)\n",
    "\n",
    "    print(\"\\n=== Baseline training ===\")\n",
    "    model_base = TinyGPT(vocab_size=tokenizer.vocab_size, cfg=cfg)\n",
    "    base_metrics = MetricsTracker(\"baseline\", use_wandb=cfg.use_wandb)\n",
    "    base_div = DiversityTracker(len(train_ds))\n",
    "\n",
    "    model_base = train_baseline(\n",
    "        cfg=cfg,\n",
    "        model=model_base,\n",
    "        train_ds=train_ds,\n",
    "        val_ds=val_ds,\n",
    "        metrics=base_metrics,\n",
    "        diversity=base_div,\n",
    "    )\n",
    "\n",
    "    base_metrics.save(f\"{cfg.save_dir}/baseline_metrics.json\")\n",
    "\n",
    "    print(\"\\n=== Router training ===\")\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    model_router = TinyGPT(vocab_size=tokenizer.vocab_size, cfg=cfg)\n",
    "    router = AttentionRouter(\n",
    "        d_input=cfg.n_chunks * cfg.d_model + 4,\n",
    "        d_k=128,\n",
    "    )\n",
    "\n",
    "    router_metrics = MetricsTracker(\"router\", use_wandb=cfg.use_wandb)\n",
    "    router_div = DiversityTracker(len(train_ds))\n",
    "\n",
    "    model_router, router = train_router(\n",
    "        cfg=cfg,\n",
    "        model=model_router,\n",
    "        router=router,\n",
    "        train_ds=train_ds,\n",
    "        val_ds=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        metrics=router_metrics,\n",
    "        diversity=router_div,\n",
    "    )\n",
    "\n",
    "    router_metrics.save(f\"{cfg.save_dir}/router_metrics.json\")\n",
    "\n",
    "    print(\"\\n=== Final comparison ===\")\n",
    "    compare_runs(base_metrics, router_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curriculum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
